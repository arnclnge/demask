---
title: "ICES_HERAS"
author: "Arienne Calonge"
date: "2025-07-31"
output: 
  html_document:
    self_contained: true
runtime: shiny
---

## Read downloaded data from the ICES data portal

```{r setup, echo=FALSE}
library(tidyverse)
library(readr)
library(leaflet)
library(CoordinateCleaner)

knitr::opts_knit$set(root.dir = "C:/Users/arienne.calonge/OneDrive - VLIZ/Ari/DEMASK/R/datras/heras")

```

```{r read, echo=FALSE, eval=FALSE}

# Set your main directory containing zip files
main_dir <- "acoustic"  # <-- Change this

# List all zip files in the folder (recursive = TRUE if subfolders)
zip_files <- list.files(main_dir, pattern = "\\.zip$", full.names = TRUE, recursive = TRUE)

# Create a folder to extract contents
unzip_dir <- file.path(main_dir, "unzipped")
dir.create(unzip_dir, showWarnings = FALSE)

# Loop through zip files
csv_list <- list()

for (zip_path in zip_files) {
  # Create a unique subfolder for each zip
  zip_name <- tools::file_path_sans_ext(basename(zip_path))
  temp_dir <- file.path(unzip_dir, zip_name)
  dir.create(temp_dir, showWarnings = FALSE)

  # Unzip
  unzip(zip_path, exdir = temp_dir)

  # Read all CSVs found in this zip
  csv_paths <- list.files(temp_dir, pattern = "\\.csv$", full.names = TRUE)
  
  for (csv in csv_paths) {
    message("Reading: ", csv)
    
    # Read all lines
    lines <- readLines(csv)

    # Split lines by section type
    #instrument_lines <- grep("^Instrument,", lines, value = TRUE)
    #calibration_lines <- grep("^Calibration,", lines, value = TRUE)
    data_lines <- grep("^Data,", lines, value = TRUE)
    #cruise_lines <- grep("^Cruise,", lines, value = TRUE)
    
    if (length(data_lines) < 2) {
    warning("Skipping ", csv, ": not enough Data lines")
    next
    }

    # Helper function to convert a section to a data.frame
    read_section <- function(section_lines) {
      header <- section_lines[1]
      records <- section_lines[-1]
      full_csv <- c(header, records)
      read.csv(text = full_csv, stringsAsFactors = FALSE)
    }

    # Now read data section
    df <- read_section(data_lines)
    
    #check df
    expected_data_headers <- c(
      "Data", "Header", "LogDistance", "LogTime", "LogLatitude", "LogLongitude",
      "LogOrigin", "LogLatitude2", "LogLongitude2", "LogOrigin2", "LogValidity",
      "LogBottomDepth", "SampleChannelDepthUpper", "SampleChannelDepthLower",
      "SamplePingAxisInterval", "SamplePingAxisIntervalType",
      "SamplePingAxisIntervalUnit", "SampleSvThreshold", "InstrumentID",
      "CalibrationID", "DataAcquisitionID", "DataProcessingID",
      "SamplePingAxisIntervalOrigin", "DataSaCategory", "EchoTypeID",
      "DataType", "DataUnit", "DataValue", "CruiseLocalID"
    )
    
    # Check headers
    actual_headers <- names(df)
    if (!identical(actual_headers, expected_data_headers)) {
      warning("Header mismatch in file: ", csv)
      print(setdiff(actual_headers, expected_data_headers))  # Unexpected columns
      print(setdiff(expected_data_headers, actual_headers))  # Missing columns
      message("incorrect headers")
      next  # Skip this file
    }
    
    csv_list[[length(csv_list) + 1]] <- df
    save(csv_list, file = "HERAS_csv_list.RData")
  }
}

# Optionally combine all CSVs into one dataframe
all_data <- do.call(rbind, csv_list)

write_csv(all_data, 'HERAS_acoustic_2015-2024.csv')

save(all_data, file = "HERAS_acoustic_2015-2024.RData")

```
Clean data
```{r checkdata, echo=FALSE, eval=FALSE}
#Check downloaded data
load("HERAS_acoustic_2015-2024.RData")

range(all_data$LogTime)
unique(all_data$DataSaCategory)

#filter to only herring
HER_data = all_data %>% filter(DataSaCategory=="HER")
range(HER_data$LogTime)

# check geographical outliers
HER_data_ <- cc_outl(HER_data,
                        lon = "LogLongitude",
                        lat = "LogLatitude",
                        species = "DataSaCategory",
                        method = "quantile",
                        mltpl = 1.5,
                        value = "flagged", #TRUE = test passed and FALSE = test failed/potentially problematic
                        sampling_thresh = 0,
                        verbose = TRUE,
                        min_occs = 7,
                        thinning = FALSE
                      )

# check statistical outliers
#create unique Row ID
    HER_data$RowID <- 1:nrow(HER_data)
    HER_data_ <- HER_data %>% filter(DataValue>mean(HER_data_$DataValue))
    
    # Calculate IQR boundaries
    Q1 <- quantile(HER_data_$DataValue, 0.25)
    Q3 <- quantile(HER_data_$DataValue, 0.75)
    IQR_val <- Q3 - Q1
    
    # Define lower and upper bounds
    lower_bound <- Q1 - 5 * IQR_val
    upper_bound <- Q3 + 5 * IQR_val
    
    # Identify outliers
    outliers <- HER_data_[HER_data_$DataValue < lower_bound | HER_data_$DataValue > upper_bound, ]%>%
      select(RowID, DataValue, DataSaCategory)%>%
      mutate(is_outlier = TRUE)

    # Flag outliers in the original dataframe
    HER_data <- HER_data %>%
        left_join(outliers %>% mutate(is_outlier = TRUE),
                  by = c("RowID", "DataValue", "DataSaCategory")) %>%
        mutate(is_outlier = ifelse(is.na(is_outlier), FALSE, is_outlier))
    
    # check NA
    colSums(is.na(HER_data))
  
    write_csv(HER_data, 'HERAS-2015-2024_proc.csv')

    save(HER_data, file = "HERAS-2015-2024_proc.RData")
    
```
Plot time series
```{r, echo=FALSE}
#plot in time series
load("HERAS-2015-2024_proc.RData")

  # Convert LogTime to POSIXct (date-time)
  HER_data$TimePosix <- as.POSIXct(HER_data$LogTime, format = "%Y-%m-%dT%H:%M", tz = "UTC")
  
  ggplot(HER_data, aes(x = TimePosix, y = DataValue)) +
  geom_point(alpha = 0.6, color = "blue") +
  labs(title = "Acoustic Backscatter (Sa) Over Time",
       x = "Time",
       y = "Sa (m²/nmi²)") +
  theme_minimal()
  
```

## Map occurrences

```{r, echo=FALSE}
# Create leaflet map
leaflet(data = HER_data) %>%
  addTiles() %>%
  addCircleMarkers(~LogLongitude, ~LogLatitude,
                   radius = 4,
                   fillOpacity = 0.7,
                   color = "blue",
                   popup = ~paste("Sa:", DataValue))

```